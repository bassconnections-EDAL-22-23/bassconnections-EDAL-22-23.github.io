<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Bass Connections 2022-2023</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  cons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: eNno
  * Updated: Mar 10 2023 with Bootstrap v5.2.3
  * Template URL: https://bootstrapmade.com/enno-free-simple-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center justify-content-between">

      <!-- <h1 class="logo"><a href="index.html">Bass Connections 2022-2023</a></h1> -->
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a> -->

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#motivation">Motivation</a></li>
          <li><a class="nav-link scrollto" href="#contributions">Contributions</a></li>
          <li><a class="nav-link scrollto" href="#methods">Methods and Materials</a></li>
          <li class="dropdown"><a href="#experiments"><span>Experiments</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="#ssl">SSL</a></li>
              <li><a href="#geonet">GeoNet Dataset</a></li>
              <li><a href="#benchmarking">Benchmarking</a></li>
              <li><a href="#experiment_design">Experiment design</a></li>
            </ul>
          </li>
          <li><a class="nav-link scrollto" href="#results">Results</a></li>
          <li><a class="nav-link scrollto" href="#takeaways">Key Takeaways</a></li>
          <li><a class="nav-link scrollto" href="#future">Future steps</a></li>
          <li><a class="nav-link scrollto" href="#team">Our Team</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero" class="d-flex align-items-center">
    <!-- <img src="assets/img/earth-satellite.jpg"/> -->

    <div class="container">
      <div class="row">
        <div class="col-lg-12 pt-5 pt-lg-0 order-2 order-lg-1 d-flex flex-column align-items-center">
          <h1>Bass Connections 2022-2023</h1>
          <h2>Tracking Climate Change With Satellites and Artificial Intelligence</h2>
          <h3>Margaret Brooks, Francesca Chiappetta, Alex Desbans, Neel Gajjar, Julia Kourelakos, Saad Lahrichi, Vaishvi
            Patel, Ruixin Zhang, Ruohan Zhang, Shufan Xia</h3>
          <div class="d-flex">
            <a href="https://github.com/energydatalab/BassConnections22-23" class="btn-get-started scrollto">Our
              Github</a>
          </div>
        </div>
      </div>
    </div>

  </section><!-- End Hero -->

  <main id="main">
    <!-- ======= Motivation Section ======= -->
    <section id="motivation" class="about">
      <div class="container">

        <div class="row">

          <div class="section-title">
            <span>Motivation</span>
            <h2>Motivation</h2>
          </div>

          <div class="col-lg-6">
            <img src="assets/img/indusriver-before.jpg" class="img-fluid" alt="">
            <img src="assets/img/indusriver-after.jpg" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <!-- <ul>
              <li><i class="bi bi-check-circle"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat</li>
              <li><i class="bi bi-check-circle"></i> Duis aute irure dolor in reprehenderit in voluptate velit</li>
              <li><i class="bi bi-check-circle"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate trideta storacalaperda</li>
            </ul> -->
            <p>
              Geospatial data has become increasingly important across disciplines as the availability of remote sensing
              data, including satellite imagery, proliferates. Large, continuous streams of data are publicly available
              from satellites such as Sentinel and Landsat. Traditionally, this data must be labeled to be used for
              machine learning models. However, labeling large datasets is expensive, requiring a lot of time and labor.
              Many large and labeled data sets are not diverse in geographic location and so cannot be generalized to
              the world. Currently, using a model pre-trained on imageNet can mitigate the need for large amounts of
              labeled data. But this method has limited application to remote sensing tasks due to the unique
              characteristics of satellite images. Recent research has shown that self-supervised learning (SSL)
              techniques have the potential to develop robust feature representations of geospatial imagery data with
              minimal task-specific labeled data, including Caron et al. (2020), Chen et al. (2020), and Calhoun et al.
              (2022). We present GeoNet, a dataset that exceeds the scale and diversity of any prior datasets, and
              evaluate its usefulness by comparing the performance of SSL models pre-trained using three different
              methods: SSL pretraining on ImageNet, SSL pretraining on GeoNet, and SSL pretraining on ImageNet further
              trained on GeoNet.
            </p>
          </div>
        </div>

      </div>
    </section><!-- End Motivation Section -->

    <!-- ======= Key Contributions Section ======= -->
    <section id="contributions" class="featured-services">
      <div class="container content">
        <div class="row">
          <div class="section-title">
            <span>Key Contributions</span>
            <h2>Key Contributions</h2>
          </div>
          <div class="col-lg-4 col-md-6">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-database"></i></div>
              <h4 class="title"><a href="#contributions">Develop GeoNet</a></h4>
              <p class="description">GeoNet is the largest and most diverse dataset to be curated for SSL in remote
                sensing. It contains over 10 million images across geographies, cities, rural regions, biomes, areas
                impacted by global change, across 8 half-seasons — the first and largest ever to capture geospatial,
                temporal, and semantic diversity for remote sensing data.</p>
            </div>
          </div>
          <div class="col-lg-4 col-md-6 mt-4 mt-md-0">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-graph-up"></i></div>
              <h4 class="title"><a href="#contributions">Test different training paradigms of SwAV on GeoNet</a></h4>
              <p class="description">Testing different training paradigms of SwAV on GeoNet to find that the use of
                GeoNet leads to state-of-the-art performance on six downstream recognition tasks in overhead imagery,
                especially in few-shot learning scenarios.</p>
            </div>
          </div>
          <div class="col-lg-4 col-md-6 mt-4 mt-lg-0">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-gear"></i></div>
              <h4 class="title"><a href="#contributions">Publish GeoEye</a></h4>
              <p class="description">GeoEye, a large pre-trained encoder for RGB imagery, significantly reduces the
                quantity of labeled data required for downstream recognition tasks, making recognition methods far more
                accessible and compute-efficient to researchers</p>
            </div>
          </div>
        </div>

      </div>
    </section><!-- End Key Contributions Section -->

    <!-- ======= Methods and Materials Section ======= -->
    <section id="methods" class="about">
      <div class="container">
        <div class="row">
          <div class="section-title">
            <span>Methods and Materials</span>
            <h2>Methods and Materials</h2>
          </div>
          <div class="col-lg-12 col-md-12">
            <p style="text-align:center">
              Our work follows the below 5 stages:
            </p>
            <div class="text-center">
              <img src="assets/img/5-stages.png" class="img-fluid" alt="" width="80%" height="auto">
            </div>

          </div>
          <div class="col-lg-6">
            <img src="assets/img/sample-distribution.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <p>
              <br />
              To create an immense dataset that captures geospatial, temporal, and semantic diversity, we select
              features
              that cover diversity across geographies (all continents and countries), cities (all major cities are
              included),
              rural regions (across all continents and countries), biomes (forests, deserts, tundra, etc.), areas
              impacted by
              global change (floods, fires, storms, etc.), across 8 half-seasons.
            </p>
            <p>
              The graph on the left shows that we draw samples from different locations covering the entire globe except
              Antarctica,
              demonstrating the geospatial diversity of GeoNet.
            </p>
          </div>
          <div class="row">
            <p class="col-lg-4 col-md-6">
              <strong>Method1</strong> consists of urban sampling and rural sampling. For urban sampling, we first draw
              samples randomly from a
              Multivariate normal (MVN) distribution centered at city centers worldwide with probability weighted by log
              (population).
              We then draw a random sample coordinate from the corresponding MVN distribution located within a 50 km
              radius.
              For rural sampling, we randomly sample locations with population densities between 5 and 250 people per
              km^2 in a
              30 X 30 arcsec (1 X 1 km at the equator approximately) resolution population density map.
            </p>
            <div class="col-lg-4 col-md-6">
              <img src="assets/img/method1_urban.png" class="img-fluid" alt="">
            </div>
            <div class="col-lg-4 col-md-6">
              <img src="assets/img/method1_rural.png" class="img-fluid" alt="">
            </div>
          </div>
          <div class="row">
            <div class="col-lg-3 col-md-6">
              <img src="assets/img/method2_built.png" class="img-fluid" alt="">
            </div>
            <div class="col-lg-3 col-md-6">
              <img src="assets/img/method3_landtype.png" class="img-fluid" alt="">
            </div>
            <div class="col-lg-3 col-md-6">
              <img src="assets/img/method4_natural_disaster.png" class="img-fluid" alt="">
            </div>
            <p class="col-lg-3 col-md-6">
              <strong>Method2</strong> includes all the coordinates of major human-built features that are associated
              with climate change,
              including airports, mining sites, power plants, ports, oil rigs, wind turbines, and dams.
              <strong>Method3</strong> uses a stratified sampling approach to include images from 10 different land
              types,
              including artificial land, cropland, grassland, tree-covered areas etc.
              <strong>Method4</strong> samples locations vulnerable to climate change-related natural disasters. For
              each category of natural disaster
              (wildfires, cyclones, droughts, and floods), we use a “proxy variable” as the probability in a weighted
              random sampling,
              which either quantifies the severity of the disaster or its occurrence frequency.
            </p>
          </div>
        </div>

      </div>
    </section><!-- End Methods and Materials Section -->

    <!-- ======= Benchmark Dataset Section ======= 
    <section id="dataset" class="about">
      <div class="container">

        <div class="row">
          <div class="section-title">
            <span>b</span>
            <h2>B</h2>
          </div>
          <div class="col-lg-6">
            <img src="assets/img/about.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <p class="fst-italic">
              Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore
              magna aliqua.
            </p>
            <ul>
              <li><i class="bi bi-check-circle"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat</li>
              <li><i class="bi bi-check-circle"></i> Duis aute irure dolor in reprehenderit in voluptate velit</li>
              <li><i class="bi bi-check-circle"></i> Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate trideta storacalaperda</li>
            </ul>
            <p>
              Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
              velit esse cillum dolore eu fugiat nulla pariatur.
            </p>
          </div>
        </div>

      </div>
    </section> End Benchmark Dataset Section -->

    <!-- ======= Experiments Section ======= -->
    <section id="experiments" class="services section-bg">
      <div class="container">

        <div class="section-title">
          <span>Experiments</span>
          <h2>Experiments</h2>
          <p>Sit sint consectetur velit quisquam cupiditate impedit suscipit alias</p>
        </div>

        <div class="row">
          <div id="ssl" class="col-lg-12 col-md-12">
            <div class="icon-box">
              <!-- <div class="icon"><i class="bx bxl-dribbble"></i></div> -->
              <h4><a href="#ssl">SSL</a></h4>
              <p>
                Historical uses of remote sensing imagery for machine learning have primarily involved supervised
                learning: the use of labeled
                input data to train a model to perform classification tasks. This requires large, labeled remote sensing
                imagery datasets. Manually
                labeling these datasets is extremely time-consuming, requires expert knowledge, and must be repeated for
                each new dataset. (ImageNet,
                one of the largest and most widely used natural image recognition datasets with 14 million training
                images, required years of human
                labeling!) Furthermore, existing datasets of this nature are limited in geographic diversity,
                representing mainly Europe and America.
                Training machine learning models on data that covers only the Global North limits their transferability
                to other parts of the world.
              </p>
              <p>
                Self-supervised learning (SSL) methods, which train a model to perform classification tasks without the
                need for labeled input data,
                address these limitations and remove the need for large, task-specific labeled datasets. Through
                pre-training on large, diverse,
                unlabeled datasets, self-supervised models learn to extract robust, highly transferable features that
                can then be applied to a wide
                range of other tasks and domains. This is highly useful for remote sensing applications.
              </p>
              <p>
                One popular SSL technique is contrastive learning, in which a model is trained to discriminate between
                positive examples (pairs of
                data that are similar in some way) and negative examples (pairs of data that are dissimilar). Many
                self-supervised learning models
                trained using contrastive learning have been shown to close the gap with and outperform supervised
                learning models. One popular SSL
                model trained using contrastive learning is SwAV (Swapping Assignments between Views), which eliminates
                the need for pairwise
                comparisons by using clustering-based methods that compare multiple views of the same image.
              </p>
              <p>
                However, commonly used pretraining datasets for self-supervised image classification and object
                detection tasks, such as ImageNet,
                have limited application to remote sensing tasks because of satellite images’ unique characteristics.
                (Images taken by satellites
                capture observations from above, come in multi-spectral bands instead of RGB, and do not include a
                unique element). We are aware of
                no equivalent to ImageNet that is specifically intended for pre-training for use with satellite imagery
                data.
              </p>
            </div>
          </div>

          <div id="geonet" class="col-lg-12 col-md-12">
            <div class="icon-box">
              <!-- <div class="icon"><i class="bx bx-file"></i></div> -->
              <h4><a href="#geonet">GeoNet Dataset</a></h4>
              <p><em>Scale</em>:&nbsp;
                Data was collected from 7.2M unique 2.24km x 2.24km areas on all continents except Antarctica. Urban and rural areas comprise 60% of the 10 million images, 19% for natural disaster areas, 20% for land use and cover, and 1% for specific built environment features.</p>
              <p><br></p>
              <p><em>Temporal Collection</em>: Furthermore, GeoNet is temporally diverse as it involved extracting Sentinel-2 images from different time periods.</p>
              
              <p><em>Sampling Strategy with Spatial Sampling:</em></p>

              <p style="margin-left: 25px;">1. Population-based Sampling:</p>

              <p style="margin-left: 50px;">Using population data, samples are generated in urban and rural regions.</p>

              <p style="margin-left: 50px;">To mimic population distribution in urban regions, samples are drawn randomly from a Multivariate normal (MVN) distribution centered at city centers worldwide with probability weighted by log (population)</p>

              <p style="margin-left: 50px;">For rural areas, locations are randomly sampled with population densities between five and 250 people per km^2 in a 30X30 arcsec (1 X 1 km at the equator approximately) resolution population density map</p>

              <p style="margin-left: 25px;">2. Targeted Built Features:</p>

              <p style="margin-left: 50px;">Seven categories of human-built features associated with climate change globally are identified using various datasets resulting in around 82,000 coordinates.</p>


              <p style="margin-left: 25px;">3. Stratified Sampling by Land Cover Types:</p>

              <p style="margin-left: 50px;">A fixed amount of coordinates are included for 11 land cover types:</p>
              <ul style="margin-left: 50px;">
                <li>
                  <p>Artificial land</p>
                </li>
                <li>
                  <p>Cropland</p>
                </li>
                <li>
                  <p>Grassland</p>
                </li>
                <li>
                  <p>Tree-covered areas</p>
                </li>
                <li>
                  <p>Shrubs-covered areas</p>
                </li>
                <li>
                  <p>Herbaceous vegetation that is aquatic or regularly flooded</p>
                </li>
                <li>
                  <p>Mangroves</p>
                </li>
                <li>
                  <p>Sparse vegetation</p>
                </li>
                <li>
                  <p>Bare soil</p>
                </li>
                <li>
                  <p>Snow and glaciers</p>
                </li>
                <li>
                  <p>Water bodies</p>
                </li>
              </ul>

              <p style="margin-left: 25px;">4. Locations Vulnerable to Natural Disasters are Included:</p>
              <ul style="margin-left: 50px">
                <li>
                  <p>Wildfires</p>
                </li>
                <li>
                  <p>Cyclones</p>
                </li>
                <li>
                  <p>Droughts</p>
                </li>
                <li>
                  <p>Floods</p>
                </li>
              </ul>
              <p><em>Sampling Strategy with a Grid-Based Approach:</em></p>

              <p style="margin-left: 25px;">Key Aim: To avoid duplications and overlaps in extracted images</p>

              <p style="margin-left: 25px;">A 2.24x2.24 km grid is defined to match the image size for SwAV&rsquo;s input dimensions (224x224) and the resolution of Sentinel-2 images (10 m). Mapping coordinates into a discrete grid allows for the removal of nearby locations with overlapping scenes.</p>

              <p style="margin-left: 25px;">Coordinated used to extract Sentinel-2 images are collected with various considerations:</p>

              <p style="margin-left: 50px;">1. 10 million samples are generated using all four sampling methods after which the corresponding grid cells that contain these coordinates are determined. Images from oversampled grid cells are deleted by limited the number of images per grid cell to 4.</p>

              <p style="margin-left: 50px;">2. If a grid cell is sampled more than once, its corresponding images from different search periods are extracted enabling seasonal temporal diversity and reducing redundancy of the view.</p>
            </div>
          </div>

          <div id="benchmarking" class="col-lg-12 col-md-12">
            <div class="icon-box">
              <!-- <div class="icon"><i class="bx bx-tachometer"></i></div> -->
              <h4><a href="#benchmarking">Benchmarking</a></h4>
              <p>
                We assemble a list of accessible, well-studied, and highly representative benchmark datasets for two
                categories of downstream tasks:
                classification and semantic segmentation. From the list, we prioritized Sentinel-2 images with a wider
                geographical coverage and
                restricted the image resolution between 0.1 and 30 m/pixel. Preprocessing is conducted so that our
                benchmark images to all be of size
                224 x 224 pixels, aligning with the image size of the GeoEye dataset used for pretraining our model. We
                evaluate GeoNet on these datasets
                by comparing its performance to the performance of fully-supervised models and other state-of-the-art
                SSL models.
              </p>
              <br/>
              <img src="assets/img/benchmark_datasets.png" class="img-fluid" alt="" width="90%">
            </div>
          </div>

          <div id="experiment_design" class="col-lg-12 col-md-12">
            <div class="icon-box">
              <!-- <div class="icon"><i class="bx bx-world"></i></div> -->
              <h4><a href="experiment_design">Experiment Design</a></h4>
              <p>
                We aim to compare the impact of different pretraining paradigms on the transfer learning performance of
                self-supervised learning
                models and fully supervised learning models. We experiment five different pretraining methods, including
                pretraining on ImageNet
                and pretraining on remote sensing datasets, as shown in the table.
              </p>
              <br/>
              <img src="assets/img/experiments.png" class="img-fluid" alt="" width="55%">
              <br/>
              <p>
                For each pretraining method, we apply and evaluate its transfer learning performance on five downstream
                benchmark inference tasks
                in table. To this end, we developed a pipeline for applying pre-training models.
              </p>
              <br/>
              <img src="assets/img/pipeline.png" class="img-fluid" alt="" width="75%">
              <br/>
              <p>
                As shown in the figure, the experiment mainly consists of two steps. First, we use the ResNet50 backbone
                from each pretrained encoder
                to extract representations. Second, we attach a decoder to the ResNet50 backbone, either Unet for
                segmentation tasks or a fully
                connected linear layer for classification tasks, and fine-tune the decoder using the labels provided by
                the benchmark dataset.
              </p>
              <br/>
              <img src="assets/img/metrics.png" class="img-fluid" alt="" width="50%">
            </div>
          </div>

        </div>

      </div>
    </section>
    <!-- End Experiments Section -->

    <!-- ======= Results Section ======= -->
    <section id="results" class="about">
      <div class="container">

        <div class="row">
          <div class="section-title">
            <span>Results</span>
            <h2>Results</h2>
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <p>
              We identified which methods perform better across training size. SwAV-3M appears to outperform other pre-training methods 
              for the SEN12MS dataset, which has weak labels. For Big Earth Net, both SwAV 3M and SwAV Imagenet perform well in multilabel 
              classification tasks, with SwAV 3M performing the best with a larger training size. For Deep Globe, SwAV-3M, SwAV Imagenet, 
              and supervised Imagenet all performed well, with supervised imagenet performing best for a lower training size and SwAV imagenet 
              performing best for a larger training size. SeCo performed noticeably worse, and MoCoV2_fMoW produced by far the lowest IOU results. 
              For Sustain Bench, SwAV 3M and SwAV Imagenet outperform other pre-training methods when the training size is small, while 
              increasing the training size, all models except SeCo perform similarly. For EuroSat, SwAV image net performs the best, and 
              unfortunately SwAV 3M does not perform better than supervised.
            </p>
            <p>
              The results of our experiments are summarized below. For each benchmark task, we plot the accuracy measurement at different training 
              size used in fine-tuning, showing each pretraining method with each separate line.
            </p>
          </div>
          <div class="col-lg-6">
            <img src="assets/img/results_table.png" class="img-fluid" alt="">
          </div>
          <div class="spacer"></div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <h4>SEN12MS</h4>
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/SEN12MS_accuracy_allsize.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/SEN12MS_loss_allsize.png" class="img-fluid" alt="">
              </div>
            </div>
            <p>
              SwAV-3M consistently outperformed SeCo, mocoV2 trained on fMoW, supervised trained on imagenet, and SwAV trained on image net on the 
              SEN12MS dataset. SEN12MS is a weakly-labeled semantic segmentation dataset, therefore all the pre-training methods are limited, 
              hence the low IoU values. The IoU score for pre-training methods increases significantly as training size increases from 64 to 1024 
              images. The results also show that self-supervision can outperform supervised on this weak label segmentation task, except for SeCo. 
            </p>
            <div class="spacer"></div>
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <h4>BigEarthNet</h4>
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/bigearthnet_accuracy.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/bigearthnet_loss.png" class="img-fluid" alt="">
              </div>
            </div>
            <p>
              SwAV-3M is comparable with SwAV trained on imagenet for this multilabel classification task,  at an f-1 score between 0.6 and 0.7. 
              SwAV-3M and SwAV trained on imagenet increase in F-1 score as training size increases more when compared to other pretraining methods.
            </p>
            <div class="spacer"></div>
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <h4>SustainBench</h4>
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/field_delineation_accuracy_allsize.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/field_delineation_loss_allsize.png" class="img-fluid" alt="">
              </div>
            </div>
            <p>
              Swav 3M and swav imageNet outperform other pretraining methods when the training size is small (64, 128, 256 and 512). However as the 
              training size increases to 1024, the marginal benefit from swav pretraining compared to other methods decreases. Pretraining SWAV on 
              3M sentinel-2 images has a small improvement from Imagnet pretraining. Overall, the best IoU score for pretraing with SWaV on both our 
              dataset and imagenet are comparable to those in Calhoun et al. (2022) at around 0.44.
            </p>
            <div class="spacer"></div>
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <h4>EuroSat</h4>
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/euroSat_accuracy_allsize.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/euroSat_loss_allsize.png" class="img-fluid" alt="">
              </div>
            </div>
            <p>
              MoCoV2, swav_imagenet, and supervised_imagenet all performed better than SwAV-3M. SeCo performed noticeably worse than the other tasks.
            </p>
            <div class="spacer"></div>
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <h4>DeepGlobe</h4>
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/deep_globe_accuracy_allsize.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/deep_globe_loss_allsize.png" class="img-fluid" alt="">
              </div>
            </div>
            <p>
              Swav_3M, swav_imagenet, and supervised_imagenet all performed the best with IOU values comparable to those in the Deep Globe paper. SeCo 
              performed noticeably worse and MoCoV2_fMoW produced by far the lowest IOU results. Multiple reruns of MoCoV2 did not result in any 
              improvements in IOU score. 
            </p>
            <div class="spacer"></div>
          </div>
        </div>

      </div>
    </section><!-- End Results Section -->

    <!-- ======= Key Takeaways Section ======= -->
    <section id="takeaways" class="featured-services">
      <div class="container content">
        <div class="row">
          <div class="section-title">
            <span>Key Takeaways</span>
            <h2>Key Takeaways</h2>
          </div>
          <div class="col-lg-4 col-md-6">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-laptop"></i></div>
              <h4 class="title"><a href="">Lorem Ipsum</a></h4>
              <p class="description">Voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint
                occaecati cupiditate non provident</p>
            </div>
          </div>
          <div class="col-lg-4 col-md-6 mt-4 mt-md-0">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-card-checklist"></i></div>
              <h4 class="title"><a href="">Dolor Sitema</a></h4>
              <p class="description">Minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
                commodo consequat tarad limino ata</p>
            </div>
          </div>
          <div class="col-lg-4 col-md-6 mt-4 mt-lg-0">
            <div class="icon-box">
              <div class="icon"><i class="bi bi-clipboard-data"></i></div>
              <h4 class="title"><a href="">Sed ut perspiciatis</a></h4>
              <p class="description">Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu
                fugiat nulla pariatur</p>
            </div>
          </div>
        </div>

      </div>
    </section><!-- End Key Rakeaways Section -->

    <!-- ======= Future Steps Section ======= -->
    <section id="future" class="about">
      <div class="container">

        <div class="row">
          <div class="section-title">
            <span>Future Steps</span>
            <h2>Future Steps</h2>
          </div>
          <div class="col-lg-6">
            <img src="assets/img/future.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6 pt-4 pt-lg-0 content">
            <p>
              Future steps in further evaluating the performance of our encoder on GeoNet could include the use of more benchmark datasets, expansion to higher resolution and addition of weak labels. Testing our encoder against benchmark datasets will more extensively show the diverse potential of its applications. Currently our dataset consists of images of resolution 10 m per pixel. We can further expand our testing on benchmark tasks which are higher in resolution and also expand the dataset to be higher resolution to see how our GeoNet self-supervised encoder performs on those tasks. 
            </p>
            <p>
              Our second hypothesis is that a natural language processing (NLP) encoder enables mappings between textual annotation and satellite images, allowing customized queries of climate data. The textual data has already been gathered and the self supervised encoder has been trained. As our next step, we want to create a natural language processing model to extract text features from the text data collected so we can support a variety of questions. Then combine those text features from the natural language encoder and the image features from our self supervised encoder from before training using the geographic data and related weak labels to both. After this combination the previously unlabeled images will now have text features. This could be presented using a basic web application that allows text searches from users and presents the related images!! 

            </p>
          </div>
        </div>

      </div>
    </section><!-- End Future Steps Section -->

    <!-- ======= Counts Section ======= -->
    <!-- <section id="counts" class="counts">
      <div class="container">

        <div class="row counters">

          <div class="col-lg-3 col-6 text-center">
            <span data-purecounter-start="0" data-purecounter-end="232" data-purecounter-duration="1" class="purecounter"></span>
            <p>Clients</p>
          </div>

          <div class="col-lg-3 col-6 text-center">
            <span data-purecounter-start="0" data-purecounter-end="521" data-purecounter-duration="1" class="purecounter"></span>
            <p>Projects</p>
          </div>

          <div class="col-lg-3 col-6 text-center">
            <span data-purecounter-start="0" data-purecounter-end="1463" data-purecounter-duration="1" class="purecounter"></span>
            <p>Hours Of Support</p>
          </div>

          <div class="col-lg-3 col-6 text-center">
            <span data-purecounter-start="0" data-purecounter-end="15" data-purecounter-duration="1" class="purecounter"></span>
            <p>Hard Workers</p>
          </div>

        </div>

      </div>
    </section> -->
    <!-- End Counts Section -->

    <!-- ======= Portfolio Section ======= -->
    <!-- <section id="portfolio" class="portfolio">
      <div class="container">

        <div class="section-title">
          <span>Portfolio</span>
          <h2>Portfolio</h2>
          <p>Sit sint consectetur velit quisquam cupiditate impedit suscipit alias</p>
        </div>

        <div class="row">
          <div class="col-lg-12 d-flex justify-content-center">
            <ul id="portfolio-flters">
              <li data-filter="*" class="filter-active">All</li>
              <li data-filter=".filter-app">App</li>
              <li data-filter=".filter-card">Card</li>
              <li data-filter=".filter-web">Web</li>
            </ul>
          </div>
        </div>

        <div class="row portfolio-container">

          <div class="col-lg-4 col-md-6 portfolio-item filter-app">
            <img src="assets/img/portfolio/portfolio-1.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>App 1</h4>
              <p>App</p>
              <a href="assets/img/portfolio/portfolio-1.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="App 1"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-web">
            <img src="assets/img/portfolio/portfolio-2.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Web 3</h4>
              <p>Web</p>
              <a href="assets/img/portfolio/portfolio-2.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Web 3"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-app">
            <img src="assets/img/portfolio/portfolio-3.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>App 2</h4>
              <p>App</p>
              <a href="assets/img/portfolio/portfolio-3.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="App 2"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-card">
            <img src="assets/img/portfolio/portfolio-4.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Card 2</h4>
              <p>Card</p>
              <a href="assets/img/portfolio/portfolio-4.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Card 2"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-web">
            <img src="assets/img/portfolio/portfolio-5.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Web 2</h4>
              <p>Web</p>
              <a href="assets/img/portfolio/portfolio-5.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Web 2"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-app">
            <img src="assets/img/portfolio/portfolio-6.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>App 3</h4>
              <p>App</p>
              <a href="assets/img/portfolio/portfolio-6.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="App 3"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-card">
            <img src="assets/img/portfolio/portfolio-7.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Card 1</h4>
              <p>Card</p>
              <a href="assets/img/portfolio/portfolio-7.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Card 1"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-card">
            <img src="assets/img/portfolio/portfolio-8.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Card 3</h4>
              <p>Card</p>
              <a href="assets/img/portfolio/portfolio-8.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Card 3"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

          <div class="col-lg-4 col-md-6 portfolio-item filter-web">
            <img src="assets/img/portfolio/portfolio-9.jpg" class="img-fluid" alt="">
            <div class="portfolio-info">
              <h4>Web 3</h4>
              <p>Web</p>
              <a href="assets/img/portfolio/portfolio-9.jpg" data-gallery="portfolioGallery" class="portfolio-lightbox preview-link" title="Web 3"><i class="bx bx-plus"></i></a>
              <a href="portfolio-details.html" class="details-link" title="More Details"><i class="bx bx-link"></i></a>
            </div>
          </div>

        </div>

      </div>
    </section> -->
    <!-- End Portfolio Section -->

    <!-- ======= Testimonials Section ======= -->
    <!-- <section id="testimonials" class="testimonials section-bg">
      <div class="container">

        <div class="section-title">
          <span>Testimonials</span>
          <h2>Testimonials</h2>
          <p>Sit sint consectetur velit quisquam cupiditate impedit suscipit alias</p>
        </div>

        <div class="testimonials-slider swiper" data-aos="fade-up" data-aos-delay="100">
          <div class="swiper-wrapper">

            <div class="swiper-slide">
              <div class="testimonial-item">
                <p>
                  <i class="bx bxs-quote-alt-left quote-icon-left"></i>
                  Proin iaculis purus consequat sem cure digni ssim donec porttitora entum suscipit rhoncus. Accusantium quam, ultricies eget id, aliquam eget nibh et. Maecen aliquam, risus at semper.
                  <i class="bx bxs-quote-alt-right quote-icon-right"></i>
                </p>
                <img src="assets/img/testimonials/testimonials-1.jpg" class="testimonial-img" alt="">
                <h3>Saul Goodman</h3>
                <h4>Ceo &amp; Founder</h4>
              </div>
            </div>

            <div class="swiper-slide">
              <div class="testimonial-item">
                <p>
                  <i class="bx bxs-quote-alt-left quote-icon-left"></i>
                  Export tempor illum tamen malis malis eram quae irure esse labore quem cillum quid cillum eram malis quorum velit fore eram velit sunt aliqua noster fugiat irure amet legam anim culpa.
                  <i class="bx bxs-quote-alt-right quote-icon-right"></i>
                </p>
                <img src="assets/img/testimonials/testimonials-2.jpg" class="testimonial-img" alt="">
                <h3>Sara Wilsson</h3>
                <h4>Designer</h4>
              </div>
            </div>

            <div class="swiper-slide">
              <div class="testimonial-item">
                <p>
                  <i class="bx bxs-quote-alt-left quote-icon-left"></i>
                  Enim nisi quem export duis labore cillum quae magna enim sint quorum nulla quem veniam duis minim tempor labore quem eram duis noster aute amet eram fore quis sint minim.
                  <i class="bx bxs-quote-alt-right quote-icon-right"></i>
                </p>
                <img src="assets/img/testimonials/testimonials-3.jpg" class="testimonial-img" alt="">
                <h3>Jena Karlis</h3>
                <h4>Store Owner</h4>
              </div>
            </div>

            <div class="swiper-slide">
              <div class="testimonial-item">
                <p>
                  <i class="bx bxs-quote-alt-left quote-icon-left"></i>
                  Fugiat enim eram quae cillum dolore dolor amet nulla culpa multos export minim fugiat minim velit minim dolor enim duis veniam ipsum anim magna sunt elit fore quem dolore labore illum veniam.
                  <i class="bx bxs-quote-alt-right quote-icon-right"></i>
                </p>
                <img src="assets/img/testimonials/testimonials-4.jpg" class="testimonial-img" alt="">
                <h3>Matt Brandon</h3>
                <h4>Freelancer</h4>
              </div>
            </div>

            <div class="swiper-slide">
              <div class="testimonial-item">
                <p>
                  <i class="bx bxs-quote-alt-left quote-icon-left"></i>
                  Quis quorum aliqua sint quem legam fore sunt eram irure aliqua veniam tempor noster veniam enim culpa labore duis sunt culpa nulla illum cillum fugiat legam esse veniam culpa fore nisi cillum quid.
                  <i class="bx bxs-quote-alt-right quote-icon-right"></i>
                </p>
                <img src="assets/img/testimonials/testimonials-5.jpg" class="testimonial-img" alt="">
                <h3>John Larson</h3>
                <h4>Entrepreneur</h4>
              </div>
            </div>

          </div>
          <div class="swiper-pagination"></div>
        </div>

      </div>
    </section> -->
    <!-- End Testimonials Section -->

    <!-- ======= Cta Section ======= -->
    <!-- <section id="cta" class="cta">
      <div class="container">

        <div class="text-center">
          <h3>Call To Action</h3>
          <p> Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
          <a class="cta-btn" href="#">Call To Action</a>
        </div>

      </div>
    </section> -->
    <!-- End Cta Section -->

    <!-- ======= Team Section ======= -->
    <section id="team" class="team section-bg">
      <div class="container">

        <div class="section-title">
          <span>Our Team</span>
          <h2>Our Team</h2>
        </div>

        <div class="row">
          <div class="content">
            <h3>Undergraduate Team Members</h3>
          </div>
          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/maggie.jpg" alt="">
              <h4>Margaret Brooks</h4>
              <p>
                Major
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/alex.png" alt="">
              <h4>Alex Desbans</h4>
              <p>
                Major
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/neel.jpeg" alt="">
              <h4>Neel Gajjar</h4>
              <p>
                Major
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/jules.png" alt="">
              <h4>Julia Kourelakos</h4>
              <p>
                Computer Science
              </p>
              <div class="social">
                <a href="https://github.com/juliakourela"><i class="bi bi-github"></i></a>
                <a href="https://www.linkedin.com/in/jules-kourelakos-505476206/"><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/saad.jpg" alt="">
              <h4>Saad Lahrichi</h4>
              <p>
                Major
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/vaishvi.jpg" alt="">
              <h4>Vaishvi Patel</h4>
              <p>
                Electrical & Computer Engineering, Computer Science
              </p>
              <div class="social">
                <a href="https://github.com/vaishvi-patel"><i class="bi bi-github"></i></a>
                <a href="https://www.linkedin.com/in/vaishvipatel/"><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/edna.png" alt="">
              <h4>Ruixin Zhang</h4>
              <p>
                Neuroscience & Computer Science, Minor in Cinematic Arts
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/ada.JPG" alt="">
              <h4>Ruohan Zhang</h4>
              <p>
                Computer Science & Mathematics
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href="https://www.linkedin.com/in/ruohan-ada-zhang/"><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>
        </div>

        <div class="row">
          <div class="content">
            <h3>Graduate Project Managers</h3>
          </div>
          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/frankie.png" alt="">
              <h4>Francesca Chiappetta</h4>
              <p>
                Graduate Program
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/shufan.png" alt="">
              <h4>Shufan Xia</h4>
              <p>
                Graduate Program
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>
        </div>

        <div class="row">
          <div class="content">
            <h3>Faculty Team Leaders</h3>
          </div>
          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/kyle.png" alt="">
              <h4>Kyle Bradbury</h4>
              <span>Pratt School of Engineering</span>
              <p>
                Electrical & Computer Engineering, Nicholas Institute for Energy, Environment, and Sustainability
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>

          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member">
              <img src="assets/img/team/jordan.png" alt="">
              <h4>Jordan Malof</h4>
              <span>Pratt School of Engineering</span>
              <p>
                Electrical & Computer Engineering, Energy Initiative
              </p>
              <div class="social">
                <a href=""><i class="bi bi-github"></i></a>
                <a href=""><i class="bi bi-linkedin"></i></a>
              </div>
            </div>
          </div>
        </div>

      </div>
    </section>
    <!-- End Team Section -->

    <!-- ======= Contact Section ======= -->
    <!-- <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <span>Contact</span>
          <h2>Contact</h2>
          <p>Sit sint consectetur velit quisquam cupiditate impedit suscipit alias</p>
        </div>

        <div class="row">

          <div class="col-lg-5 d-flex align-items-stretch">
            <div class="info">
              <div class="address">
                <i class="bi bi-geo-alt"></i>
                <h4>Location:</h4>
                <p>A108 Adam Street, New York, NY 535022</p>
              </div>

              <div class="email">
                <i class="bi bi-envelope"></i>
                <h4>Email:</h4>
                <p>info@example.com</p>
              </div>

              <div class="phone">
                <i class="bi bi-phone"></i>
                <h4>Call:</h4>
                <p>+1 5589 55488 55s</p>
              </div>

              <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d12097.433213460943!2d-74.0062269!3d40.7101282!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0xb89d1fe6bc499443!2sDowntown+Conference+Center!5e0!3m2!1smk!2sbg!4v1539943755621" frameborder="0" style="border:0; width: 100%; height: 290px;" allowfullscreen></iframe>
            </div>

          </div>

          <div class="col-lg-7 mt-5 mt-lg-0 d-flex align-items-stretch">
            <form action="forms/contact.php" method="post" role="form" class="php-email-form">
              <div class="row">
                <div class="form-group col-md-6">
                  <label for="name">Your Name</label>
                  <input type="text" name="name" class="form-control" id="name" required>
                </div>
                <div class="form-group col-md-6 mt-3 mt-md-0">
                  <label for="name">Your Email</label>
                  <input type="email" class="form-control" name="email" id="email" required>
                </div>
              </div>
              <div class="form-group mt-3">
                <label for="name">Subject</label>
                <input type="text" class="form-control" name="subject" id="subject" required>
              </div>
              <div class="form-group mt-3">
                <label for="name">Message</label>
                <textarea class="form-control" name="message" rows="10" required></textarea>
              </div>
              <div class="my-3">
                <div class="loading">Loading</div>
                <div class="error-message"></div>
                <div class="sent-message">Your message has been sent. Thank you!</div>
              </div>
              <div class="text-center"><button type="submit">Send Message</button></div>
            </form>
          </div>

        </div>

      </div>
    </section> -->
    <!-- End Contact Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

    <div class="footer-top">

      <div class="container">

        <div class="row justify-content-center">
          <div class="col-lg-6">
            <h3>Bass Connections 2022-2023</h3>
            <p>Tracking Climate Change With Satellites and Artificial Intelligence</p>
          </div>
        </div>
        <div class="row justify-content-center">
          <div class="col-lg-12 pt-5 pt-lg-0 order-2 order-lg-1 d-flex flex-column align-items-center">
            <a href="https://github.com/energydatalab/BassConnections22-23" class="btn btn-get-started scrollto">Our
              Github <i class="bi bi-github"> </i></a>
          </div>
          
        </div>

      </div>
    </div>

    <div class="container footer-bottom clearfix">
      <div class="copyright">
        &copy; Copyright <strong><span>eNno</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/enno-free-simple-bootstrap-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>